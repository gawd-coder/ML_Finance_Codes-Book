<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="../resources/style.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="machine-learning-in-finance-from-theory-to-practice">Machine Learning in Finance: From Theory to Practice</h1>
<h2 id="chapter-5-interpretability">Chapter 5: Interpretability</h2>
<p>This chapter contains the following notebooks.</p>
<p>For instructions on how to set up the Python environment and run the notebooks please refer to <a href="../SETUP.html">SETUP.html</a> in the <em>ML_Finance_Codes</em> directory.</p>
<h3 id="ml_in_finance-deep-learning-interpretability.ipynb">ML_in_Finance-Deep-Learning-Interpretability.ipynb</h3>
<ul>
<li>The purpose of this notebook is to illustrate a neural network interpretability method which is compatible with linear regression.</li>
<li>We generate data from such a linear regression model, train a neural network on this data, and show that the neural network gradients approximate the regression model coefficients.</li>
<li>Various simple experimental tests, corresponding to Section 4 of Chpt 5, are performed to illustrate the properties of network interpretability.</li>
</ul>
<h3 id="ml_in_finance-deep-learning-interaction.ipynb">ML_in_Finance-Deep-Learning-Interaction.ipynb</h3>
<ul>
<li>This notebook illustrates a neural network interpretability method which is compatible with linear regression, including an interaction term.</li>
<li>We generate data from such a linear regression model, train a neural network on this data, and show that the neural network gradients approximate the regression model coefficients.</li>
<li>Various simple experimental tests, corresponding to Section 4 of Chpt 5, are performed to illustrate the properties of network interpretability.</li>
</ul>
<h3 id="ml_in_finance-deep-factor-models.ipynb">ML_in_Finance-Deep-Factor-Models.ipynb</h3>
<ul>
<li>The purpose of this notebook is to demonstrate the application of deep learning to fundamental factor modeling. The outputs are monthly excess returns, the inputs are fundamental factor loadings (BARRA style). The data provided has already been normalized.</li>
<li>The notebook describes the data loading, training using walk-forward optimization, performance evaluation and comparison with OLS regression. The dataset consists of 6 fundamental factors for 218 stocks over a 100 month period starting in February 2008.</li>
<li>See the description of the smaller dataset described in Section 6.2 of Chpt 5. See Table 5.4 for a description of the factors.</li>
</ul>
</body>
</html>
