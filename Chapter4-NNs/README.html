<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="../resources/style.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="machine-learning-in-finance-from-theory-to-practice">Machine Learning in Finance: From Theory to Practice</h1>
<h2 id="chapter-4-neural-networks">Chapter 4: Neural Networks</h2>
<p>This chapter contains the following notebooks.</p>
<p>For instructions on how to set up the Python environment and run the notebooks please refer to <a href="../SETUP.html">SETUP.html</a> in the <em>ML_Finance_Codes</em> directory.</p>
<h3 id="ml_in_finance-deep-classifiers.ipynb">ML_in_Finance-Deep-Classifiers.ipynb</h3>
<p>This notebook corresponds to Section 2.2 of Chapter 4 and demonstrates the configuration and properties of feed-forward neural networks. Several neural networks of increasing complexity are created to investigate how the perceptron units transform the input space. Beginning with a single-layer perceptron, before adding one and then two hidden layers, we study the fitted weights and plot the separating hyperplanes. The effect of changing the number of perceptron units in a layer is also demonstrated.</p>
<h3 id="ml_in_finance-backpropagation.ipynb">ML_in_Finance-Backpropagation.ipynb</h3>
<p>This notebooks demonstrate the back-propagation algorithm, applied to a three layer feed-forward network. The process of creating and training the same neural network in Keras is then shown to compare the results. Refer to Section 5.1 of Chapter 4 for further details.</p>
<h3 id="ml_finance_bayesian_neural_network.ipynb">ML_Finance_Bayesian_Neural_Network.ipynb</h3>
<p>This notebook corresponds to Section 6 in Chapter 4 and demonstrates the application of Bayesian neural networks to the half-moon problem. The material is more advanced and provided for completeness as Bayesian modeling was covered in earlier chapters. The notebook uses variational inference, implemented in PyMC3.</p>
</body>
</html>
